ğŸ§  Next Word Prediction Using LSTM

A deep learning project that predicts the next word in a sentence using an LSTM-based language model trained on Shakespeareâ€™s Hamlet. The project includes a full NLP pipeline â€” from data preprocessing and sequence generation to model training, evaluation, and deployment with Streamlit.

ğŸš€ Project Features

Uses Long Short-Term Memory (LSTM) networks for sequence prediction

Trained on the full text of Shakespeareâ€™s Hamlet

End-to-end workflow: preprocessing â†’ training â†’ evaluation â†’ deployment

Streamlit web app for real-time prediction

Implements early stopping to reduce overfitting

ğŸ“Œ Tech Stack
Component	Technology
Programming Language	Python
Deep Learning	TensorFlow / Keras
NLP Tools	Tokenizer, Embedding, Padding
Deployment	Streamlit
Dataset	Shakespeare â€” Hamlet
ğŸ“‚ Project Structure
â”œâ”€â”€ data/
â”‚   â””â”€â”€ hamlet.txt
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ model_training.ipynb
â”œâ”€â”€ saved_model/
â”œâ”€â”€ streamlit_app.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

ğŸ”§ How It Works
1ï¸âƒ£ Data Preprocessing

Load and clean raw text

Tokenize text and map each word to an index

Generate inputâ€“output word sequences

Pad sequences to uniform length

2ï¸âƒ£ Model Architecture

Embedding layer

Two stacked LSTM layers

Dense layer with softmax for next-word probability

3ï¸âƒ£ Training

Optimizer: Adam

Loss: Categorical Cross-Entropy

Early stopping to prevent overfitting

4ï¸âƒ£ Evaluation

Tested on example inputs to measure prediction accuracy and sentence coherence.

ğŸŒ Streamlit Web App

Run locally:

pip install -r requirements.txt
streamlit run streamlit_app.py


Enter any sentence and get the predicted next word in real time.
Example:

Input: To be or not to
Output: be

ğŸ“ˆ Results

The trained model shows strong ability to auto-complete text and capture linguistic style of Shakespearean writing.
Example generations:

Input	Predicted Next Word
"The king shall never"	speak
"My lord I have"	done
"To be or not to"	be
ğŸ› ï¸ Setup & Installation
git clone <your-repo-link>
cd <repo-name>
pip install -r requirements.txt

ğŸ“Œ Future Improvements

Train on larger multi-author corpora

Use Bidirectional LSTM / Transformer for improved performance

Predict multiple future words instead of one

Add model export & API mode

ğŸ¤ Contributing

Contributions are welcome!
Feel free to open issues or submit pull requests ğŸ’¡

ğŸ“œ License

This project is licensed under the MIT License.

Contributions are welcome!
Feel free to open issues or submit pull requests ğŸ’¡

ğŸ“œ License

This project is licensed under the MIT License.
